[2024-09-30T18:31:48.674+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-09-30T18:31:48.694+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: reddit_pipeline.reddit_extration manual__2024-09-30T18:31:47.991313+00:00 [queued]>
[2024-09-30T18:31:48.701+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: reddit_pipeline.reddit_extration manual__2024-09-30T18:31:47.991313+00:00 [queued]>
[2024-09-30T18:31:48.702+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-09-30T18:31:48.713+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): reddit_extration> on 2024-09-30 18:31:47.991313+00:00
[2024-09-30T18:31:48.717+0000] {standard_task_runner.py:63} INFO - Started process 77 to run task
[2024-09-30T18:31:48.720+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'reddit_pipeline', 'reddit_extration', 'manual__2024-09-30T18:31:47.991313+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmp3abvqvyg']
[2024-09-30T18:31:48.722+0000] {standard_task_runner.py:91} INFO - Job 14: Subtask reddit_extration
[2024-09-30T18:31:48.763+0000] {task_command.py:426} INFO - Running <TaskInstance: reddit_pipeline.reddit_extration manual__2024-09-30T18:31:47.991313+00:00 [running]> on host d18f347f1f63
[2024-09-30T18:31:48.840+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Haziq' AIRFLOW_CTX_DAG_ID='reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extration' AIRFLOW_CTX_EXECUTION_DATE='2024-09-30T18:31:47.991313+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-09-30T18:31:47.991313+00:00'
[2024-09-30T18:31:48.841+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-09-30T18:31:48.853+0000] {logging_mixin.py:188} INFO - connected to reddit hello
[2024-09-30T18:31:50.056+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'For side projects, I\'m always thinking of new use/edge cases "maybe this way is better", "maybe that way", "this isn\'t following best practice" which leads me to constant refactoring of my code and ultimately hindering real progress.\n\nAnyone else been here before?\n\nHow do you curb this desire to refactor all the time?\n\nThe sad thing is, **I know** that you should just get something out there that works - then iterate, but I still find myself spending hours refactoring an ingestion method (for example).', 'author_fullname': 't2_4gzaf8mv', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How do you deal with the constant perfectionist desire to continually refactor your code', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsroq7', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 47, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 47, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727689530.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>For side projects, I&#39;m always thinking of new use/edge cases &quot;maybe this way is better&quot;, &quot;maybe that way&quot;, &quot;this isn&#39;t following best practice&quot; which leads me to constant refactoring of my code and ultimately hindering real progress.</p>\n\n<p>Anyone else been here before?</p>\n\n<p>How do you curb this desire to refactor all the time?</p>\n\n<p>The sad thing is, <strong>I know</strong> that you should just get something out there that works - then iterate, but I still find myself spending hours refactoring an ingestion method (for example).</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fsroq7', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='theoriginalmantooth'), 'discussion_type': None, 'num_comments': 25, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsroq7/how_do_you_deal_with_the_constant_perfectionist/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsroq7/how_do_you_deal_with_the_constant_perfectionist/', 'subreddit_subscribers': 217166, 'created_utc': 1727689530.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.057+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hello. I’m here for a help.\n\nOn a project I work we have a requirement to display on a dashboard a widget that shows finished jobs statistics for last 24 hours. Particularly how many jobs finished with complete, failed or complete with warning statuses.\n\nWe use MySql. Jobs table stores about 2 billions of records overall. Jobs are connected to a particular tenant. The biggest one generates 5 millions of jobs every 24 hours. So in the worst case scenario aggregation happens over 5 millions of records.\n\nAs I mentioned, the data is displayed on UI so getting the result should be fast enough to not worsen user experience. \n\nThe solution we consider to apply is pre-aggregation by 1 minute buckets. And deriving 24 hours result on user request by summing up the buckets matching 24 hours timespan.\n\nHow do you think, is the solution feasible? Do you have better alternatives?', 'author_fullname': 't2_hydrppjg', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': ' Near realtime aggregation of big data volume ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsbdf6', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 16, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 16, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727635122.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello. I’m here for a help.</p>\n\n<p>On a project I work we have a requirement to display on a dashboard a widget that shows finished jobs statistics for last 24 hours. Particularly how many jobs finished with complete, failed or complete with warning statuses.</p>\n\n<p>We use MySql. Jobs table stores about 2 billions of records overall. Jobs are connected to a particular tenant. The biggest one generates 5 millions of jobs every 24 hours. So in the worst case scenario aggregation happens over 5 millions of records.</p>\n\n<p>As I mentioned, the data is displayed on UI so getting the result should be fast enough to not worsen user experience. </p>\n\n<p>The solution we consider to apply is pre-aggregation by 1 minute buckets. And deriving 24 hours result on user request by summing up the buckets matching 24 hours timespan.</p>\n\n<p>How do you think, is the solution feasible? Do you have better alternatives?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fsbdf6', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Hot_Warning_8551'), 'discussion_type': None, 'num_comments': 15, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsbdf6/near_realtime_aggregation_of_big_data_volume/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsbdf6/near_realtime_aggregation_of_big_data_volume/', 'subreddit_subscribers': 217166, 'created_utc': 1727635122.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.057+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I am working as bw4hana consultant now with 2.6 years experience and have a quiet knowledge on sql, python and some Azure DLFE. My management is suggesting three option to choose carrer path one in snowflake or to continue in sap they said I should go with SAC and Datasphere(DWC) or go with azure having knowledge in powerbi.\nWhat is best to choose for long career?', 'author_fullname': 't2_yppbt10z0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What should I choose SAP BW path or snowflake?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fst02k', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 12, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 12, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727694900.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am working as bw4hana consultant now with 2.6 years experience and have a quiet knowledge on sql, python and some Azure DLFE. My management is suggesting three option to choose carrer path one in snowflake or to continue in sap they said I should go with SAC and Datasphere(DWC) or go with azure having knowledge in powerbi.\nWhat is best to choose for long career?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1fst02k', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Elegant-Muscle8849'), 'discussion_type': None, 'num_comments': 9, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fst02k/what_should_i_choose_sap_bw_path_or_snowflake/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fst02k/what_should_i_choose_sap_bw_path_or_snowflake/', 'subreddit_subscribers': 217166, 'created_utc': 1727694900.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.058+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'How do you guys do data validations and quality checks of the data ? post ETL ? or you have inline way of doing it. and what would you prefer ?', 'author_fullname': 't2_zybaevfvl', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'inline data quality for ETL pipeline ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsi3yl', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 9, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 9, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727653466.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>How do you guys do data validations and quality checks of the data ? post ETL ? or you have inline way of doing it. and what would you prefer ?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1fsi3yl', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='dataoculus'), 'discussion_type': None, 'num_comments': 12, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsi3yl/inline_data_quality_for_etl_pipeline/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsi3yl/inline_data_quality_for_etl_pipeline/', 'subreddit_subscribers': 217166, 'created_utc': 1727653466.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.058+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I'm a Data Engineer with a Master's in Information Systems and a Bachelor's minor in CS. I've spent 2.5 years as a Junior Data Engineer and have now been working as a Data Engineer for 2 years. Thanks to some key projects I executed, I helped my boss get recognition in the C-suite, and now I’ve got an opportunity to pick my next move: Senior Data Engineer or Solution Architect.\n\nI like both options. I’m strong in design, but I also love getting my hands dirty with implementation. I’ve not only built classic data analytics solutions like datalakehouses etc. but also handled a lot of integrations between systems. Should I go for Solution Architect, focusing more on system design and integration, or should I first become a Senior Data Engineer and prove that I am a very technical guy before stepping up? I could use some guidance here on what’s the better move for growth and career impact.", 'author_fullname': 't2_793tedn0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Senior Data Engineer vs. Solution Architect', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsycps', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1727712512.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727710211.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m a Data Engineer with a Master&#39;s in Information Systems and a Bachelor&#39;s minor in CS. I&#39;ve spent 2.5 years as a Junior Data Engineer and have now been working as a Data Engineer for 2 years. Thanks to some key projects I executed, I helped my boss get recognition in the C-suite, and now I’ve got an opportunity to pick my next move: Senior Data Engineer or Solution Architect.</p>\n\n<p>I like both options. I’m strong in design, but I also love getting my hands dirty with implementation. I’ve not only built classic data analytics solutions like datalakehouses etc. but also handled a lot of integrations between systems. Should I go for Solution Architect, focusing more on system design and integration, or should I first become a Senior Data Engineer and prove that I am a very technical guy before stepping up? I could use some guidance here on what’s the better move for growth and career impact.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1fsycps', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Ok-Sentence-8542'), 'discussion_type': None, 'num_comments': 15, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsycps/senior_data_engineer_vs_solution_architect/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsycps/senior_data_engineer_vs_solution_architect/', 'subreddit_subscribers': 217166, 'created_utc': 1727710211.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.059+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I\'m starting a greenfield project at my existing company that needs to combine some typical data engineering tasks (ingestion, transformation, data quality checks) and a few ML related tasks (classification, evaluation and writing results). \n\nCurrently we are on GCP and using cloud scheduler to schedule Python scripts based on a schedule. This is mainly already done for the data engineering tasks while the ML tasks will still need to be build on top of that. \n\nWe are given the freedom to look at introducing a task orchestrator into this process and replace cloud scheduler, given that tasks can be i) scheduled and ii) run in a sequence as a DAG. \n\nA few requirements:\n\n* I\'d like to minimize the devops/infra overhead and use managed services as much as possible. (self-hosting can be a big pain) \n* I\'d like to keep the compute element contained within GCP (e.g. model training, data transformation). \n* The orchestrator should easily integrate with GCP services like BigQuery, Cloud Run, Vertex AI. But also with tools like Slack, Email, etc. \n* It should easily scale to hundreds/thousands of "workflows" that can be orchestrated in parallel. \n* Local development should be relatively easy without needing to deploy everything on your own machine. \n\nI\'ve been looking into a few orchestration tools, mainly Airflow and Dagster. I already have quite some experience with Airflow, and cloud composer in GCP can make life easier to deploy Airflow. Now I also have dealt with the pain of using Airflow and know how difficult it can be to build complex DAGs and make sure that everything keeps running (multi-DAG backfill anyone?). Also cloud composer seems quite expensive by the looks of it (GKE cluster + service costs). Especially when deploying it multiple environments (dev/pre-prod/prod). \n\nOn the other hand, the design principles of Dagster appeal to me with its data assets approach and integrations with frameworks like Pytorch. However, I\'m wondering how to best deal with deployment. Is it possible to use a managed Dagster and still do the compute just within GCP? How would that work for pricing? \n\nI found plenty of threads and blogs that compare orchestrators but I\'m wondering what you would pick in this situation? ', 'author_fullname': 't2_r8um2zbq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Picking a data and ML orchestrator', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsepoy', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.74, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727643799.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;m starting a greenfield project at my existing company that needs to combine some typical data engineering tasks (ingestion, transformation, data quality checks) and a few ML related tasks (classification, evaluation and writing results). </p>\n\n<p>Currently we are on GCP and using cloud scheduler to schedule Python scripts based on a schedule. This is mainly already done for the data engineering tasks while the ML tasks will still need to be build on top of that. </p>\n\n<p>We are given the freedom to look at introducing a task orchestrator into this process and replace cloud scheduler, given that tasks can be i) scheduled and ii) run in a sequence as a DAG. </p>\n\n<p>A few requirements:</p>\n\n<ul>\n<li>I&#39;d like to minimize the devops/infra overhead and use managed services as much as possible. (self-hosting can be a big pain) </li>\n<li>I&#39;d like to keep the compute element contained within GCP (e.g. model training, data transformation). </li>\n<li>The orchestrator should easily integrate with GCP services like BigQuery, Cloud Run, Vertex AI. But also with tools like Slack, Email, etc. </li>\n<li>It should easily scale to hundreds/thousands of &quot;workflows&quot; that can be orchestrated in parallel. </li>\n<li>Local development should be relatively easy without needing to deploy everything on your own machine. </li>\n</ul>\n\n<p>I&#39;ve been looking into a few orchestration tools, mainly Airflow and Dagster. I already have quite some experience with Airflow, and cloud composer in GCP can make life easier to deploy Airflow. Now I also have dealt with the pain of using Airflow and know how difficult it can be to build complex DAGs and make sure that everything keeps running (multi-DAG backfill anyone?). Also cloud composer seems quite expensive by the looks of it (GKE cluster + service costs). Especially when deploying it multiple environments (dev/pre-prod/prod). </p>\n\n<p>On the other hand, the design principles of Dagster appeal to me with its data assets approach and integrations with frameworks like Pytorch. However, I&#39;m wondering how to best deal with deployment. Is it possible to use a managed Dagster and still do the compute just within GCP? How would that work for pricing? </p>\n\n<p>I found plenty of threads and blogs that compare orchestrators but I&#39;m wondering what you would pick in this situation? </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1fsepoy', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='mediumcanned'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsepoy/picking_a_data_and_ml_orchestrator/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsepoy/picking_a_data_and_ml_orchestrator/', 'subreddit_subscribers': 217166, 'created_utc': 1727643799.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.059+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I am an analyst on a team of four. Most of the data we use is exported out of difference systems, which is insanely time consuming and we sometimes lose historicals.\n\nThe team and I do not work with APIs. Though willing to learn, IT prefers us not to. I'm okay with this.\n\nI requested that IT provides us with a SQL database, where they pull data in from a multitude of systems. We are now being given a data warehouse, leveraging a fact-dimension model.\n\nThis is completely new to me and the team. The consultants building the table do not fully understand the data and have not extracted the necessary business requirements from us-- the people using the data.\n\nShould an analyst be expected to already have knowledge regarding data warehouse infrastructure? We just need access to data that we normally can't get at.\n\nNow we have dimension tables that consolidate data from multiple sources, where the consultants are essentially merging columns they believe to be synonymous with each other. They are transforming data.\n\nAs a user of the data, I do not fully understand what is happening behind the scenes, which makes it difficult to use the data.\n\nMost of the team's reporting is concerned with what's in each system, as opposed to a holistic view. Why do we have these fact and dimension tables as opposed to tables that are isolated to their specific system?\n\nThe consultants building the data warehouse are leveraging a medallion model, and all I care about is the silver.", 'author_fullname': 't2_bdhprh7p', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[Data Warehouse] Fact & Dimension Tables', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsu963', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727699154.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am an analyst on a team of four. Most of the data we use is exported out of difference systems, which is insanely time consuming and we sometimes lose historicals.</p>\n\n<p>The team and I do not work with APIs. Though willing to learn, IT prefers us not to. I&#39;m okay with this.</p>\n\n<p>I requested that IT provides us with a SQL database, where they pull data in from a multitude of systems. We are now being given a data warehouse, leveraging a fact-dimension model.</p>\n\n<p>This is completely new to me and the team. The consultants building the table do not fully understand the data and have not extracted the necessary business requirements from us-- the people using the data.</p>\n\n<p>Should an analyst be expected to already have knowledge regarding data warehouse infrastructure? We just need access to data that we normally can&#39;t get at.</p>\n\n<p>Now we have dimension tables that consolidate data from multiple sources, where the consultants are essentially merging columns they believe to be synonymous with each other. They are transforming data.</p>\n\n<p>As a user of the data, I do not fully understand what is happening behind the scenes, which makes it difficult to use the data.</p>\n\n<p>Most of the team&#39;s reporting is concerned with what&#39;s in each system, as opposed to a holistic view. Why do we have these fact and dimension tables as opposed to tables that are isolated to their specific system?</p>\n\n<p>The consultants building the data warehouse are leveraging a medallion model, and all I care about is the silver.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fsu963', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='eclecticnewt'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsu963/data_warehouse_fact_dimension_tables/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsu963/data_warehouse_fact_dimension_tables/', 'subreddit_subscribers': 217166, 'created_utc': 1727699154.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.060+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '', 'author_fullname': 't2_baajg5kk', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Solve Governance Debt with Data Products', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 70, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsuflw', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.64, 'author_flair_background_color': None, 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/MQBS0FmTE-ej5sYinCajO0bqy3D8g55i6p8jA7RRfqA.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1727699693.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'moderndata101.substack.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://moderndata101.substack.com/p/solve-governance-debt-with-data-products', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/el_B5rtJYCvmnh38XayGjq2pcWVfmWqSXWkNRYya9Lo.jpg?auto=webp&s=594ec3428e9ff75a13f9be686752009188ac0a8d', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/el_B5rtJYCvmnh38XayGjq2pcWVfmWqSXWkNRYya9Lo.jpg?width=108&crop=smart&auto=webp&s=1cf60432f6c3b088237568cb94a520028b858f93', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/el_B5rtJYCvmnh38XayGjq2pcWVfmWqSXWkNRYya9Lo.jpg?width=216&crop=smart&auto=webp&s=8e165200ea79ae5cde4efee2cb316ef8b958e669', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/el_B5rtJYCvmnh38XayGjq2pcWVfmWqSXWkNRYya9Lo.jpg?width=320&crop=smart&auto=webp&s=81ece58d9cf190df9fbb901f84fdec9a4d64f9cf', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/el_B5rtJYCvmnh38XayGjq2pcWVfmWqSXWkNRYya9Lo.jpg?width=640&crop=smart&auto=webp&s=021d694d26901cbb293f5ec5afcbb67d41a99093', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/el_B5rtJYCvmnh38XayGjq2pcWVfmWqSXWkNRYya9Lo.jpg?width=960&crop=smart&auto=webp&s=6c00b7ff5217652f185714f3bac7b73d46271d3e', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/el_B5rtJYCvmnh38XayGjq2pcWVfmWqSXWkNRYya9Lo.jpg?width=1080&crop=smart&auto=webp&s=f3f7bb803d06ebba39332f187f550448d51d79f0', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'WnOauntdPGv_wz-rCAsQ4V7FA0ku9Vh20jXOHlk5AxM'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1fsuflw', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='growth_man'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsuflw/solve_governance_debt_with_data_products/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://moderndata101.substack.com/p/solve-governance-debt-with-data-products', 'subreddit_subscribers': 217166, 'created_utc': 1727699693.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.060+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hello everyone! \nMe and some colleagues want to get a data catalog. Mostly to document our data. We want to store the catalog in our own environment. I checked some tools, but it’s not so easy to pick the right one. \n\nDo you have some tools that you would recommend? ', 'author_fullname': 't2_5dsqe79d', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data Catalog', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fszcxn', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727712608.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello everyone! \nMe and some colleagues want to get a data catalog. Mostly to document our data. We want to store the catalog in our own environment. I checked some tools, but it’s not so easy to pick the right one. </p>\n\n<p>Do you have some tools that you would recommend? </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fszcxn', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Juwapcizi'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fszcxn/data_catalog/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fszcxn/data_catalog/', 'subreddit_subscribers': 217166, 'created_utc': 1727712608.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.060+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi everyone\n\n  \nIm looking to get some advice as I haven\'t found much resources about this (feel free to point me to some if I\'m just not good at researching) \n\n  \nIt is my first time to join an architecture that is trying to implement "Data-As-A-Product" approach, typically I work on the more traditional architecture in my previous companies, and this current one is moving from that traditional into this new paradigm\n\n  \nHere is my understanding so far\n\n  \n- It seems that the Source Data Product side of things more closely aligns to my traditional understanding, their implementation is that it still has bronze-silver-gold (or however youd like to call it) (this one is still in the process of being created but it is already mentioned that the bronze-silver-gold will be implemented)\n\n- We receive the gold layer of the SDP from the main data engineering team, and I receive it in my own team as my team\'s data engineer that delivers specific reports\n\n- Im to create the Analytical Data Product. This is to serve specific use cases for our reports\n\n- Extra context: Our business group will be one of the first recipients of data from SDP. Kind of a guinea pig.\n\nQuestions:\n\n- How do I approach modeling this? Since the SDP is going to deliver a gold layer, what is there to model?\n\n- Connected to my above question but with an assumption, if the gold layer is already fit for reports, do I just end up doing basically some aggregations and report specific columns?\n\n- Is there anything I am misunderstanding with the approach?\n\n  \nIf there are any gaps in the context, please feel free to point it out and I\'ll add on to it\n\nWould love to hear for your guys\' advice\n\n  \nThanks!', 'author_fullname': 't2_e5a6k', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data Modeling the Analytical Data Product', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsred6', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727688223.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi everyone</p>\n\n<p>Im looking to get some advice as I haven&#39;t found much resources about this (feel free to point me to some if I&#39;m just not good at researching) </p>\n\n<p>It is my first time to join an architecture that is trying to implement &quot;Data-As-A-Product&quot; approach, typically I work on the more traditional architecture in my previous companies, and this current one is moving from that traditional into this new paradigm</p>\n\n<p>Here is my understanding so far</p>\n\n<ul>\n<li><p>It seems that the Source Data Product side of things more closely aligns to my traditional understanding, their implementation is that it still has bronze-silver-gold (or however youd like to call it) (this one is still in the process of being created but it is already mentioned that the bronze-silver-gold will be implemented)</p></li>\n<li><p>We receive the gold layer of the SDP from the main data engineering team, and I receive it in my own team as my team&#39;s data engineer that delivers specific reports</p></li>\n<li><p>Im to create the Analytical Data Product. This is to serve specific use cases for our reports</p></li>\n<li><p>Extra context: Our business group will be one of the first recipients of data from SDP. Kind of a guinea pig.</p></li>\n</ul>\n\n<p>Questions:</p>\n\n<ul>\n<li><p>How do I approach modeling this? Since the SDP is going to deliver a gold layer, what is there to model?</p></li>\n<li><p>Connected to my above question but with an assumption, if the gold layer is already fit for reports, do I just end up doing basically some aggregations and report specific columns?</p></li>\n<li><p>Is there anything I am misunderstanding with the approach?</p></li>\n</ul>\n\n<p>If there are any gaps in the context, please feel free to point it out and I&#39;ll add on to it</p>\n\n<p>Would love to hear for your guys&#39; advice</p>\n\n<p>Thanks!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fsred6', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='kittehkillah'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsred6/data_modeling_the_analytical_data_product/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsred6/data_modeling_the_analytical_data_product/', 'subreddit_subscribers': 217166, 'created_utc': 1727688223.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.061+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "We're a SaaS company with approximately 1000 customers.\n\nOur current data stack is:\nMySQL -> Stitch -> Snowflake -> DBT Cloud -> Semantic Layer\n\nWe've developed numerous interesting data points in Snowflake that would be beneficial for our customers. We want to share this data using a frontend that we've built ourselves. Hence, no bundling dashboards from BI tools.\n\nWe were hoping to use the GraphQL API that DBT semantic layer exports, but that was way too slow.\nWe are now looking at querying Snowflake directly from our backend and then caching that data.\n\nHas anyone implemented a similar solution or have insights to share? \nAny potential pitfalls or challenges we should be aware of?\nDo you think this is a good approach for sharing data back to our product?\nThanks", 'author_fullname': 't2_hdne94r2', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to share Snowflake data back to our SaaS product', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1ft0c9v', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727714991.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>We&#39;re a SaaS company with approximately 1000 customers.</p>\n\n<p>Our current data stack is:\nMySQL -&gt; Stitch -&gt; Snowflake -&gt; DBT Cloud -&gt; Semantic Layer</p>\n\n<p>We&#39;ve developed numerous interesting data points in Snowflake that would be beneficial for our customers. We want to share this data using a frontend that we&#39;ve built ourselves. Hence, no bundling dashboards from BI tools.</p>\n\n<p>We were hoping to use the GraphQL API that DBT semantic layer exports, but that was way too slow.\nWe are now looking at querying Snowflake directly from our backend and then caching that data.</p>\n\n<p>Has anyone implemented a similar solution or have insights to share? \nAny potential pitfalls or challenges we should be aware of?\nDo you think this is a good approach for sharing data back to our product?\nThanks</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1ft0c9v', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Frrusty'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1ft0c9v/how_to_share_snowflake_data_back_to_our_saas/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ft0c9v/how_to_share_snowflake_data_back_to_our_saas/', 'subreddit_subscribers': 217166, 'created_utc': 1727714991.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.061+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi!, so I’m in the first class/batch/whatever of data science students in my country, naturally there isn’t exactly anyone (locally) i can ask about the upcoming years of my career besides the profs, I figured why not ask people who *are* in the field about the nature of how jobs are going to be\n\n\nWe’re set to hopefully graduate with a bachelor degree next year, hope we paint a good picture about tech student around the world :)', 'author_fullname': 't2_54l95kw8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'First gen data science ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1ft07un', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727714691.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi!, so I’m in the first class/batch/whatever of data science students in my country, naturally there isn’t exactly anyone (locally) i can ask about the upcoming years of my career besides the profs, I figured why not ask people who <em>are</em> in the field about the nature of how jobs are going to be</p>\n\n<p>We’re set to hopefully graduate with a bachelor degree next year, hope we paint a good picture about tech student around the world :)</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1ft07un', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='zbady20'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1ft07un/first_gen_data_science/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ft07un/first_gen_data_science/', 'subreddit_subscribers': 217166, 'created_utc': 1727714691.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.061+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi everyone, I just checked that Fivetran does the full load sync of Mongodb fast comparable to other tools, Just wanted to know what they are doing internally. Can anyone help here?', 'author_fullname': 't2_uduoa3p8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How Fivetran Does Full Load of Mongodb?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsp967', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.76, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727678262.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi everyone, I just checked that Fivetran does the full load sync of Mongodb fast comparable to other tools, Just wanted to know what they are doing internally. Can anyone help here?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fsp967', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='hashcode-ankit'), 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsp967/how_fivetran_does_full_load_of_mongodb/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsp967/how_fivetran_does_full_load_of_mongodb/', 'subreddit_subscribers': 217166, 'created_utc': 1727678262.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.062+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'SAP HANA the next gen in memory db what are you thoughts about it ?\n', 'author_fullname': 't2_r8g7ng6kq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Sap hana the next best?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1ft1pml', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727718343.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>SAP HANA the next gen in memory db what are you thoughts about it ?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1ft1pml', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Outside-Wave3387'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1ft1pml/sap_hana_the_next_best/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ft1pml/sap_hana_the_next_best/', 'subreddit_subscribers': 217166, 'created_utc': 1727718343.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.062+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hello everyone,  \nI am designing a Data Platform and there is a requirement to use DATAIKU as an ETL tool. We have a security requirement for mTLS connections. In the guide, there is no mention of using the mTLS certificate when connecting via S3. The S3 storage we are using is DELL's ECS. Does anyone know how I could set up this connection? Does Dataiku support it?  \nThank you!", 'author_fullname': 't2_zgymrtu17', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Dataiku Connection to an S3 storage compatible with mTLS', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fst04f', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727694906.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello everyone,<br/>\nI am designing a Data Platform and there is a requirement to use DATAIKU as an ETL tool. We have a security requirement for mTLS connections. In the guide, there is no mention of using the mTLS certificate when connecting via S3. The S3 storage we are using is DELL&#39;s ECS. Does anyone know how I could set up this connection? Does Dataiku support it?<br/>\nThank you!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fst04f', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Comfortable-Bit9406'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fst04f/dataiku_connection_to_an_s3_storage_compatible/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fst04f/dataiku_connection_to_an_s3_storage_compatible/', 'subreddit_subscribers': 217166, 'created_utc': 1727694906.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.062+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I Just booked dbt Analytics Engineering Certification Exam for next week. For this exam, I am relying on the courses mentioned in this [pdf](https://8698602.fs1.hubspotusercontent-na1.net/hubfs/8698602/dbt_analytics_engineering_certification_exam_study_guide.pdf) for dbt core, and some 4-5 month of experience in working with dbt core and snowflake for a corporate(mostly with seeds, incremental tables and views). \n\nIf anyone have already taken the test, I would like to know if there will be any questions regarding dbt cloud or not? How difficult could the questions be to understand?  \nAlso, if you guys have any resources or experiences to share, I would highly appreciate it :)\n\nThank you,', 'author_fullname': 't2_dda8zr28', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Trying to take "dbt Analytics Engineering Certification Exam"', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsotpp', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.57, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727676331.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I Just booked dbt Analytics Engineering Certification Exam for next week. For this exam, I am relying on the courses mentioned in this <a href="https://8698602.fs1.hubspotusercontent-na1.net/hubfs/8698602/dbt_analytics_engineering_certification_exam_study_guide.pdf">pdf</a> for dbt core, and some 4-5 month of experience in working with dbt core and snowflake for a corporate(mostly with seeds, incremental tables and views). </p>\n\n<p>If anyone have already taken the test, I would like to know if there will be any questions regarding dbt cloud or not? How difficult could the questions be to understand?<br/>\nAlso, if you guys have any resources or experiences to share, I would highly appreciate it :)</p>\n\n<p>Thank you,</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1fsotpp', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='seeker114'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsotpp/trying_to_take_dbt_analytics_engineering/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsotpp/trying_to_take_dbt_analytics_engineering/', 'subreddit_subscribers': 217166, 'created_utc': 1727676331.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.063+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'State your platform/tool/language/system and then complete the following prompt: \n\nEverything was going smoothly until...', 'author_fullname': 't2_3m4ael9f', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Writing prompt', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fskl5v', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.42, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727661213.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>State your platform/tool/language/system and then complete the following prompt: </p>\n\n<p>Everything was going smoothly until...</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1fskl5v', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Almostasleeprightnow'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fskl5v/writing_prompt/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fskl5v/writing_prompt/', 'subreddit_subscribers': 217166, 'created_utc': 1727661213.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.063+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '\nWhat would you do to improve metric quality, analyses, sources of truth, etc?', 'author_fullname': 't2_6ajx8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'You have 300k. How do you improve data quality for the business?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fsuqhf', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.42, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727700595.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>What would you do to improve metric quality, analyses, sources of truth, etc?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1fsuqhf', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Teddy_Raptor'), 'discussion_type': None, 'num_comments': 14, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fsuqhf/you_have_300k_how_do_you_improve_data_quality_for/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsuqhf/you_have_300k_how_do_you_improve_data_quality_for/', 'subreddit_subscribers': 217166, 'created_utc': 1727700595.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.063+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7fded8bb3fa0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi everyone. I am Anish, working as a Data Engineer at a Big4 firm. With little over 1 year experience, I have built data pipelines and maintain them using Azure Data stack that involved Azure Synapse Analytics, Pyspark coding and Azure Devops for CICD.\n\nHere is my LinkedIn profile. Feel free to suggest and advise how to navigate further in this industry.\n\nhttps://www.linkedin.com/in/anish-dey-a50a99132?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app\n\n', 'author_fullname': 't2_8f3fcvxo', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': "Let's Connect", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1fspf3e', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.23, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1727678997.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi everyone. I am Anish, working as a Data Engineer at a Big4 firm. With little over 1 year experience, I have built data pipelines and maintain them using Azure Data stack that involved Azure Synapse Analytics, Pyspark coding and Azure Devops for CICD.</p>\n\n<p>Here is my LinkedIn profile. Feel free to suggest and advise how to navigate further in this industry.</p>\n\n<p><a href="https://www.linkedin.com/in/anish-dey-a50a99132?utm_source=share&amp;utm_campaign=share_via&amp;utm_content=profile&amp;utm_medium=android_app">https://www.linkedin.com/in/anish-dey-a50a99132?utm_source=share&amp;utm_campaign=share_via&amp;utm_content=profile&amp;utm_medium=android_app</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1fspf3e', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Automatic_Till_9363'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1fspf3e/lets_connect/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fspf3e/lets_connect/', 'subreddit_subscribers': 217166, 'created_utc': 1727678997.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-09-30T18:31:50.063+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-09-30T18:31:50.064+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-09-30T18:31:50.072+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=reddit_pipeline, task_id=reddit_extration, run_id=manual__2024-09-30T18:31:47.991313+00:00, execution_date=20240930T183147, start_date=20240930T183148, end_date=20240930T183150
[2024-09-30T18:31:50.098+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-09-30T18:31:50.113+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-09-30T18:31:50.115+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
