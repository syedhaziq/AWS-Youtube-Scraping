[2024-09-30T18:39:15.548+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-09-30T18:39:15.576+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: reddit_pipeline.reddit_extration manual__2024-09-30T18:39:14.293111+00:00 [queued]>
[2024-09-30T18:39:15.588+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: reddit_pipeline.reddit_extration manual__2024-09-30T18:39:14.293111+00:00 [queued]>
[2024-09-30T18:39:15.589+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-09-30T18:39:15.604+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): reddit_extration> on 2024-09-30 18:39:14.293111+00:00
[2024-09-30T18:39:15.611+0000] {standard_task_runner.py:63} INFO - Started process 85 to run task
[2024-09-30T18:39:15.614+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'reddit_pipeline', 'reddit_extration', 'manual__2024-09-30T18:39:14.293111+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmparhli6ab']
[2024-09-30T18:39:15.615+0000] {standard_task_runner.py:91} INFO - Job 18: Subtask reddit_extration
[2024-09-30T18:39:15.663+0000] {task_command.py:426} INFO - Running <TaskInstance: reddit_pipeline.reddit_extration manual__2024-09-30T18:39:14.293111+00:00 [running]> on host d18f347f1f63
[2024-09-30T18:39:15.742+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Haziq' AIRFLOW_CTX_DAG_ID='reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extration' AIRFLOW_CTX_EXECUTION_DATE='2024-09-30T18:39:14.293111+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-09-30T18:39:14.293111+00:00'
[2024-09-30T18:39:15.743+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-09-30T18:39:15.755+0000] {logging_mixin.py:188} INFO - connected to reddit hello
[2024-09-30T18:39:16.865+0000] {logging_mixin.py:188} INFO - {'id': '1fsroq7', 'title': 'How do you deal with the constant perfectionist desire to continually refactor your code', 'score': 53, 'num_comments': 25, 'author': Redditor(name='theoriginalmantooth'), 'created_utc': 1727689530.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsroq7/how_do_you_deal_with_the_constant_perfectionist/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.865+0000] {logging_mixin.py:188} INFO - {'id': '1fsbdf6', 'title': ' Near realtime aggregation of big data volume ', 'score': 14, 'num_comments': 15, 'author': Redditor(name='Hot_Warning_8551'), 'created_utc': 1727635122.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsbdf6/near_realtime_aggregation_of_big_data_volume/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.866+0000] {logging_mixin.py:188} INFO - {'id': '1fst02k', 'title': 'What should I choose SAP BW path or snowflake?', 'score': 10, 'num_comments': 9, 'author': Redditor(name='Elegant-Muscle8849'), 'created_utc': 1727694900.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fst02k/what_should_i_choose_sap_bw_path_or_snowflake/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.866+0000] {logging_mixin.py:188} INFO - {'id': '1fsi3yl', 'title': 'inline data quality for ETL pipeline ?', 'score': 11, 'num_comments': 12, 'author': Redditor(name='dataoculus'), 'created_utc': 1727653466.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsi3yl/inline_data_quality_for_etl_pipeline/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.867+0000] {logging_mixin.py:188} INFO - {'id': '1fsycps', 'title': 'Senior Data Engineer vs. Solution Architect', 'score': 7, 'num_comments': 15, 'author': Redditor(name='Ok-Sentence-8542'), 'created_utc': 1727710211.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsycps/senior_data_engineer_vs_solution_architect/', 'over_18': False, 'edited': 1727712512.0, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.867+0000] {logging_mixin.py:188} INFO - {'id': '1fsepoy', 'title': 'Picking a data and ML orchestrator', 'score': 5, 'num_comments': 1, 'author': Redditor(name='mediumcanned'), 'created_utc': 1727643799.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsepoy/picking_a_data_and_ml_orchestrator/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.867+0000] {logging_mixin.py:188} INFO - {'id': '1fsu963', 'title': '[Data Warehouse] Fact & Dimension Tables', 'score': 5, 'num_comments': 6, 'author': Redditor(name='eclecticnewt'), 'created_utc': 1727699154.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsu963/data_warehouse_fact_dimension_tables/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.868+0000] {logging_mixin.py:188} INFO - {'id': '1fsuflw', 'title': 'Solve Governance Debt with Data Products', 'score': 3, 'num_comments': 0, 'author': Redditor(name='growth_man'), 'created_utc': 1727699693.0, 'url': 'https://moderndata101.substack.com/p/solve-governance-debt-with-data-products', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.869+0000] {logging_mixin.py:188} INFO - {'id': '1fszcxn', 'title': 'Data Catalog', 'score': 3, 'num_comments': 1, 'author': Redditor(name='Juwapcizi'), 'created_utc': 1727712608.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fszcxn/data_catalog/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.869+0000] {logging_mixin.py:188} INFO - {'id': '1fsred6', 'title': 'Data Modeling the Analytical Data Product', 'score': 3, 'num_comments': 6, 'author': Redditor(name='kittehkillah'), 'created_utc': 1727688223.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsred6/data_modeling_the_analytical_data_product/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.869+0000] {logging_mixin.py:188} INFO - {'id': '1ft0c9v', 'title': 'How to share Snowflake data back to our SaaS product', 'score': 2, 'num_comments': 4, 'author': Redditor(name='Frrusty'), 'created_utc': 1727714991.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ft0c9v/how_to_share_snowflake_data_back_to_our_saas/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.870+0000] {logging_mixin.py:188} INFO - {'id': '1ft07un', 'title': 'First gen data science ', 'score': 4, 'num_comments': 4, 'author': Redditor(name='zbady20'), 'created_utc': 1727714691.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ft07un/first_gen_data_science/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.870+0000] {logging_mixin.py:188} INFO - {'id': '1fsp967', 'title': 'How Fivetran Does Full Load of Mongodb?', 'score': 2, 'num_comments': 8, 'author': Redditor(name='hashcode-ankit'), 'created_utc': 1727678262.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsp967/how_fivetran_does_full_load_of_mongodb/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.870+0000] {logging_mixin.py:188} INFO - {'id': '1ft1pml', 'title': 'Sap hana the next best?', 'score': 2, 'num_comments': 6, 'author': Redditor(name='Outside-Wave3387'), 'created_utc': 1727718343.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1ft1pml/sap_hana_the_next_best/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.871+0000] {logging_mixin.py:188} INFO - {'id': '1fst04f', 'title': 'Dataiku Connection to an S3 storage compatible with mTLS', 'score': 1, 'num_comments': 0, 'author': Redditor(name='Comfortable-Bit9406'), 'created_utc': 1727694906.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fst04f/dataiku_connection_to_an_s3_storage_compatible/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.871+0000] {logging_mixin.py:188} INFO - {'id': '1fsotpp', 'title': 'Trying to take "dbt Analytics Engineering Certification Exam"', 'score': 1, 'num_comments': 4, 'author': Redditor(name='seeker114'), 'created_utc': 1727676331.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsotpp/trying_to_take_dbt_analytics_engineering/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.871+0000] {logging_mixin.py:188} INFO - {'id': '1fskl5v', 'title': 'Writing prompt', 'score': 0, 'num_comments': 0, 'author': Redditor(name='Almostasleeprightnow'), 'created_utc': 1727661213.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fskl5v/writing_prompt/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.872+0000] {logging_mixin.py:188} INFO - {'id': '1fsuqhf', 'title': 'You have 300k. How do you improve data quality for the business?', 'score': 0, 'num_comments': 14, 'author': Redditor(name='Teddy_Raptor'), 'created_utc': 1727700595.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fsuqhf/you_have_300k_how_do_you_improve_data_quality_for/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.872+0000] {logging_mixin.py:188} INFO - {'id': '1fspf3e', 'title': "Let's Connect", 'score': 0, 'num_comments': 0, 'author': Redditor(name='Automatic_Till_9363'), 'created_utc': 1727678997.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1fspf3e/lets_connect/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}
[2024-09-30T18:39:16.872+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-09-30T18:39:16.873+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-09-30T18:39:16.881+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=reddit_pipeline, task_id=reddit_extration, run_id=manual__2024-09-30T18:39:14.293111+00:00, execution_date=20240930T183914, start_date=20240930T183915, end_date=20240930T183916
[2024-09-30T18:39:16.913+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-09-30T18:39:16.928+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-09-30T18:39:16.931+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
